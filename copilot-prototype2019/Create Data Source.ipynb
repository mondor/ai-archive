{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_index length: 11703\n",
      "max sequence 11703\n",
      "max word index before save 11703\n",
      "max word index after save 11703\n",
      "['pebble', 'beach', 'qu', 'alia', 'a', 'very', 'merry', 'christmas', 'from', 'the', 'pebbles', 'beach', 'team', 'hamilton', 'island', 'qu', 'alia', 'great', 'barrier', 'reef', 'christmas']\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0  704    5   73   76    8\n",
      "  480  400   92   37    3 3655    5  435    2    1   73   76   21   25\n",
      "   16   92]\n",
      "word_index length: 1862\n",
      "max sequence 1862\n",
      "max word index before save 1862\n",
      "max word index after save 1862\n",
      "['furniture', 'portrait', 'woman', 'head', 'clothing', 'man', 'accessories', 'smile', 'hat', 'person', 'glasses', 'kid', 'child', 'girl', 'photography', 'crowd', 'en', 'human', 'face', 'cap', 'apparel', 'tie', 'chair', 'laughing', 'photo', 'party', 'female', 'selfie', 'accessory', 'beard', 'costume', 'people']\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  67  53  47 264  17  88  56 151 109   8 137 141 128  61  50 263   1   9\n",
      "  49 207  18 665 101 344  51 375  40 132  57 541 426  27]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0, '/Users/mondormo/stackla17/stackla-web/etc/python')\n",
    "from create_datasource import build_sequence\n",
    "\n",
    "build_sequence('input/data/training', 150, 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('input/data/training/train.csv', header=None)\n",
    "train = train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.basename('/a/c/d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 1], [1, 2, 2]]\n",
      "{'compose': 1, 'multiple': 2, 'this': 3, 'is': 4, 'a': 5, 'sentence': 6, 'of': 7}\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "text = [\n",
    "    'this is a sentence compose of multiple compose'.split(),\n",
    "    'this is a sentence compose of multiple multiple'.split()\n",
    "]\n",
    "\n",
    "tokenizer = Tokenizer(filters='!\"$%&()*+,-./:;<=>?[\\\\]^`{|}~\\t\\n', \n",
    "                          num_words=3, \n",
    "                          lower=True, \n",
    "                          char_level=False)\n",
    "    \n",
    "tokenizer.fit_on_texts(text)\n",
    "word_seq = tokenizer.texts_to_sequences(text)\n",
    "print(word_seq)\n",
    "print(tokenizer.word_index)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
