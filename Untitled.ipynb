{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a torch.Size([2, 5, 2])\n",
      "b torch.Size([2, 2])\n",
      "a + b: tensor([[[3., 4.],\n",
      "         [3., 4.],\n",
      "         [3., 4.],\n",
      "         [3., 4.],\n",
      "         [3., 4.]],\n",
      "\n",
      "        [[3., 4.],\n",
      "         [3., 4.],\n",
      "         [3., 4.],\n",
      "         [3., 4.],\n",
      "         [3., 4.]]])\n",
      "softmax a:  torch.Size([2, 5, 2])\n",
      "att size torch.Size([2, 5])\n",
      "alpha size torch.Size([2, 5, 1])\n",
      "mul size torch.Size([2, 5, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.,  5.],\n",
       "        [10., 10.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones((2,5,2)) # (batch_size, num_pixels, attention_dim)\n",
    "b = torch.Tensor([[2,3], [2,3]]) # (batch_size, attention_dim)\n",
    "\n",
    "\n",
    "print('a', a.shape)\n",
    "print('b', b.shape)\n",
    "full_att = nn.Linear(2, 1)\n",
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "print('a + b:', (a + b.unsqueeze(1)))\n",
    "add = full_att((a + b.unsqueeze(1)))\n",
    "att = add.squeeze(2)\n",
    "\n",
    "print('softmax a: ',softmax(a).shape)\n",
    "print('att size', att.shape)\n",
    "alpha = softmax(att)\n",
    "\n",
    "\n",
    "\n",
    "print('alpha size', torch.Tensor([[[1],[1],[1],[1],[1]], [[2],[2],[2],[2],[2]]]).shape)\n",
    "mul = (a * torch.Tensor([[[1],[1],[1],[1],[1]], [[2],[2],[2],[2],[2]]]))\n",
    "\n",
    "print('mul size', mul.shape)\n",
    "mul.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[3.3523e-04],\n",
      "         [1.2332e-04],\n",
      "         [9.9929e-01],\n",
      "         [1.2332e-04],\n",
      "         [1.2332e-04]],\n",
      "\n",
      "        [[2.4701e-03],\n",
      "         [3.3430e-04],\n",
      "         [9.9653e-01],\n",
      "         [3.3430e-04],\n",
      "         [3.3430e-04]]])\n",
      "tensor([[[3.3523e-04],\n",
      "         [1.2332e-04],\n",
      "         [9.9929e-01],\n",
      "         [1.2332e-04],\n",
      "         [1.2332e-04]],\n",
      "\n",
      "        [[2.4701e-03],\n",
      "         [3.3430e-04],\n",
      "         [9.9653e-01],\n",
      "         [3.3430e-04],\n",
      "         [3.3430e-04]]])\n",
      "tensor([[[3.3523e-04, 3.3523e-04, 3.3523e-04, 3.3523e-04, 3.3523e-04,\n",
      "          3.3523e-04, 3.3523e-04, 3.3523e-04, 3.3523e-04, 3.3523e-04,\n",
      "          3.3523e-04, 3.3523e-04, 3.3523e-04, 3.3523e-04, 3.3523e-04,\n",
      "          3.3523e-04, 3.3523e-04, 3.3523e-04, 3.3523e-04, 3.3523e-04],\n",
      "         [1.2332e-04, 1.2332e-04, 1.2332e-04, 1.2332e-04, 1.2332e-04,\n",
      "          1.2332e-04, 1.2332e-04, 1.2332e-04, 1.2332e-04, 1.2332e-04,\n",
      "          1.2332e-04, 1.2332e-04, 1.2332e-04, 1.2332e-04, 1.2332e-04,\n",
      "          1.2332e-04, 1.2332e-04, 1.2332e-04, 1.2332e-04, 1.2332e-04],\n",
      "         [9.9929e-01, 9.9929e-01, 9.9929e-01, 9.9929e-01, 9.9929e-01,\n",
      "          9.9929e-01, 9.9929e-01, 9.9929e-01, 9.9929e-01, 9.9929e-01,\n",
      "          9.9929e-01, 9.9929e-01, 9.9929e-01, 9.9929e-01, 9.9929e-01,\n",
      "          9.9929e-01, 9.9929e-01, 9.9929e-01, 9.9929e-01, 9.9929e-01],\n",
      "         [1.2332e-04, 1.2332e-04, 1.2332e-04, 1.2332e-04, 1.2332e-04,\n",
      "          1.2332e-04, 1.2332e-04, 1.2332e-04, 1.2332e-04, 1.2332e-04,\n",
      "          1.2332e-04, 1.2332e-04, 1.2332e-04, 1.2332e-04, 1.2332e-04,\n",
      "          1.2332e-04, 1.2332e-04, 1.2332e-04, 1.2332e-04, 1.2332e-04],\n",
      "         [1.2332e-04, 1.2332e-04, 1.2332e-04, 1.2332e-04, 1.2332e-04,\n",
      "          1.2332e-04, 1.2332e-04, 1.2332e-04, 1.2332e-04, 1.2332e-04,\n",
      "          1.2332e-04, 1.2332e-04, 1.2332e-04, 1.2332e-04, 1.2332e-04,\n",
      "          1.2332e-04, 1.2332e-04, 1.2332e-04, 1.2332e-04, 1.2332e-04]],\n",
      "\n",
      "        [[2.4701e-03, 2.4701e-03, 2.4701e-03, 2.4701e-03, 2.4701e-03,\n",
      "          2.4701e-03, 2.4701e-03, 2.4701e-03, 2.4701e-03, 2.4701e-03,\n",
      "          2.4701e-03, 2.4701e-03, 2.4701e-03, 2.4701e-03, 2.4701e-03,\n",
      "          2.4701e-03, 2.4701e-03, 2.4701e-03, 2.4701e-03, 2.4701e-03],\n",
      "         [3.3430e-04, 3.3430e-04, 3.3430e-04, 3.3430e-04, 3.3430e-04,\n",
      "          3.3430e-04, 3.3430e-04, 3.3430e-04, 3.3430e-04, 3.3430e-04,\n",
      "          3.3430e-04, 3.3430e-04, 3.3430e-04, 3.3430e-04, 3.3430e-04,\n",
      "          3.3430e-04, 3.3430e-04, 3.3430e-04, 3.3430e-04, 3.3430e-04],\n",
      "         [9.9653e-01, 9.9653e-01, 9.9653e-01, 9.9653e-01, 9.9653e-01,\n",
      "          9.9653e-01, 9.9653e-01, 9.9653e-01, 9.9653e-01, 9.9653e-01,\n",
      "          9.9653e-01, 9.9653e-01, 9.9653e-01, 9.9653e-01, 9.9653e-01,\n",
      "          9.9653e-01, 9.9653e-01, 9.9653e-01, 9.9653e-01, 9.9653e-01],\n",
      "         [3.3430e-04, 3.3430e-04, 3.3430e-04, 3.3430e-04, 3.3430e-04,\n",
      "          3.3430e-04, 3.3430e-04, 3.3430e-04, 3.3430e-04, 3.3430e-04,\n",
      "          3.3430e-04, 3.3430e-04, 3.3430e-04, 3.3430e-04, 3.3430e-04,\n",
      "          3.3430e-04, 3.3430e-04, 3.3430e-04, 3.3430e-04, 3.3430e-04],\n",
      "         [3.3430e-04, 3.3430e-04, 3.3430e-04, 3.3430e-04, 3.3430e-04,\n",
      "          3.3430e-04, 3.3430e-04, 3.3430e-04, 3.3430e-04, 3.3430e-04,\n",
      "          3.3430e-04, 3.3430e-04, 3.3430e-04, 3.3430e-04, 3.3430e-04,\n",
      "          3.3430e-04, 3.3430e-04, 3.3430e-04, 3.3430e-04, 3.3430e-04]]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones((2,5,20))\n",
    "b = torch.Tensor([[[1],[0],[9],[0],[0]], [[2],[0],[8],[0],[0]]])\n",
    "softmax = nn.Softmax(dim=1)\n",
    "print(softmax(b))\n",
    "print(softmax(b.squeeze(2)).unsqueeze(2))\n",
    "print(a * softmax(b))\n",
    "print( (a * softmax(b)).sum(dim=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 5., 5., 5., 5., 5., 5., 5., 5., 5.],\n",
       "        [5., 5., 5., 5., 5., 5., 5., 5., 5., 5.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = torch.ones((2,5,10))\n",
    "d.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = torch.ones((2,5,10))\n",
    "e[:,1,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 4.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = torch.Tensor([[[2,2], [1,2]]])\n",
    "f.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 7])\n",
      "torch.return_types.max(\n",
      "values=tensor([[5.]]),\n",
      "indices=tensor([[4]]))\n",
      "torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "g = torch.Tensor([[[1,2,3,4,5,1,2]]])\n",
    "print(g.shape)\n",
    "print(g.max(2))\n",
    "max_num, max_pos = g.max(2)\n",
    "print(max_pos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1])\n",
      "torch.Size([1, 1, 1, 265])\n"
     ]
    }
   ],
   "source": [
    "embed = nn.Embedding(1000, 265)\n",
    "\n",
    "inp = torch.LongTensor([[[4]]])\n",
    "print(inp.shape)\n",
    "print(embed(inp).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2000],\n",
      "         [0.2000],\n",
      "         [0.2000],\n",
      "         [0.2000],\n",
      "         [0.2000]],\n",
      "\n",
      "        [[0.2000],\n",
      "         [0.2000],\n",
      "         [0.2000],\n",
      "         [0.2000],\n",
      "         [0.2000]]])\n",
      "torch.Size([2, 5, 1])\n",
      "tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]])\n",
      "torch.Size([2, 5])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones((2,5,1)) # (batch_size, num_pixels, attention_dim)\n",
    "\n",
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "print(softmax(a))\n",
    "print(softmax(a).shape)\n",
    "print(softmax(a).squeeze(2))\n",
    "print(softmax(a).squeeze(2).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]])\n",
      "torch.Size([2, 5])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones((2,5,1)) # (batch_size, num_pixels, attention_dim)\n",
    "\n",
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "print(softmax(a.squeeze(2)))\n",
    "print(softmax(a.squeeze(2)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.]]])\n",
      "tensor([[[1., 1., 1., 1., 1., 1., 1.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[2., 2., 2., 2., 2., 2., 2.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros((2,5,7))\n",
    "print(a)\n",
    "\n",
    "a[:, 0, :] = torch.Tensor([[1,1,1,1,1,1,1], [2,2,2,2,2,2,2]])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.4800e-01, -2.5583e-01, -2.6328e-01,  5.3386e-03, -3.8100e-04,\n",
      "           7.4484e-02,  3.4020e-02,  2.0592e-01],\n",
      "         [-2.0533e-01, -3.6150e-01, -2.9054e-01,  7.8541e-03,  4.0717e-03,\n",
      "           2.2192e-01,  6.0805e-02,  3.5667e-01],\n",
      "         [-2.4437e-01, -4.0961e-01, -2.9030e-01,  9.4030e-03,  5.2893e-03,\n",
      "           3.3811e-01,  8.0997e-02,  4.6430e-01],\n",
      "         [-2.7393e-01, -4.3244e-01, -2.8709e-01,  1.0310e-02,  4.4946e-03,\n",
      "           4.1698e-01,  9.7174e-02,  5.3654e-01],\n",
      "         [-2.9619e-01, -4.4352e-01, -2.8426e-01,  1.0824e-02,  2.9846e-03,\n",
      "           4.6855e-01,  1.1006e-01,  5.8384e-01]],\n",
      "\n",
      "        [[-1.4800e-01, -2.5583e-01, -2.6328e-01,  5.3386e-03, -3.8100e-04,\n",
      "           7.4484e-02,  3.4020e-02,  2.0592e-01],\n",
      "         [-2.0533e-01, -3.6150e-01, -2.9054e-01,  7.8541e-03,  4.0717e-03,\n",
      "           2.2192e-01,  6.0805e-02,  3.5667e-01],\n",
      "         [-2.4437e-01, -4.0961e-01, -2.9030e-01,  9.4030e-03,  5.2893e-03,\n",
      "           3.3811e-01,  8.0997e-02,  4.6430e-01],\n",
      "         [-2.7393e-01, -4.3244e-01, -2.8709e-01,  1.0310e-02,  4.4946e-03,\n",
      "           4.1698e-01,  9.7174e-02,  5.3654e-01],\n",
      "         [-2.9619e-01, -4.4352e-01, -2.8426e-01,  1.0824e-02,  2.9846e-03,\n",
      "           4.6855e-01,  1.1006e-01,  5.8384e-01]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[-0.2962, -0.4435, -0.2843,  0.0108,  0.0030,  0.4685,  0.1101,\n",
      "           0.5838],\n",
      "         [-0.2962, -0.4435, -0.2843,  0.0108,  0.0030,  0.4685,  0.1101,\n",
      "           0.5838]]], grad_fn=<StackBackward>)\n",
      "tensor([[-0.2962, -0.4435, -0.2843,  0.0108,  0.0030,  0.4685,  0.1101,  0.5838],\n",
      "        [-0.2962, -0.4435, -0.2843,  0.0108,  0.0030,  0.4685,  0.1101,  0.5838]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "lstm = nn.LSTM(20, 8, 1, batch_first=True)\n",
    "a = torch.ones((2,5,20))\n",
    "\n",
    "out, (h, c) = lstm(a)\n",
    "print(out) # batch, seq_len, 8\n",
    "print(h) # layer, batch, 8\n",
    "print(h[-1,:,:])\n",
    "print(h[-1,:,:].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CVND_Exercises",
   "language": "python",
   "name": "cvnd_exercises"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
