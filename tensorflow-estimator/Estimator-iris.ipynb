{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "TRAIN_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
    "\n",
    "def maybe_download():\n",
    "    train_path = tf.keras.utils.get_file(TRAIN_URL.split('/')[-1], TRAIN_URL)\n",
    "    test_path = tf.keras.utils.get_file(TEST_URL.split('/')[-1], TEST_URL)\n",
    "    return train_path, test_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth',\n",
    "                    'PetalLength', 'PetalWidth', 'Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(y_name='Species'):\n",
    "    train_path, test_path = maybe_download()\n",
    "    train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "    train_x, train_y = train, train.pop(y_name)\n",
    "    \n",
    "    test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "    test_x, test_y = test, test.pop(y_name)\n",
    "    \n",
    "    return (train_x, train_y), (test_x, test_y)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x, train_y), (test_x, test_y) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      5.6\n",
       "1      3.3\n",
       "2      4.5\n",
       "3      1.5\n",
       "4      1.7\n",
       "5      1.3\n",
       "6      1.5\n",
       "7      5.1\n",
       "8      4.4\n",
       "9      1.5\n",
       "10     3.9\n",
       "11     4.9\n",
       "12     1.2\n",
       "13     1.7\n",
       "14     6.7\n",
       "15     4.7\n",
       "16     5.9\n",
       "17     6.6\n",
       "18     5.3\n",
       "19     1.5\n",
       "20     5.7\n",
       "21     5.6\n",
       "22     1.3\n",
       "23     5.6\n",
       "24     5.8\n",
       "25     1.5\n",
       "26     4.0\n",
       "27     5.1\n",
       "28     4.5\n",
       "29     5.0\n",
       "      ... \n",
       "90     5.2\n",
       "91     4.7\n",
       "92     1.4\n",
       "93     1.5\n",
       "94     5.8\n",
       "95     1.4\n",
       "96     1.4\n",
       "97     6.7\n",
       "98     4.8\n",
       "99     1.6\n",
       "100    1.4\n",
       "101    3.3\n",
       "102    1.3\n",
       "103    4.1\n",
       "104    1.6\n",
       "105    1.4\n",
       "106    1.5\n",
       "107    1.4\n",
       "108    3.6\n",
       "109    1.6\n",
       "110    4.9\n",
       "111    4.1\n",
       "112    1.6\n",
       "113    6.0\n",
       "114    1.6\n",
       "115    4.4\n",
       "116    4.2\n",
       "117    1.4\n",
       "118    1.4\n",
       "119    3.7\n",
       "Name: PetalLength, Length: 120, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(train_x)['PetalLength']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn(features, labels, batch_size):\n",
    "    \"\"\"An input function for training\"\"\"\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # Shuffle, repeat, and batch the examples.\n",
    "    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n",
    "\n",
    "    # Return the dataset.\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def eval_input_fn(features, labels, batch_size):\n",
    "    \"\"\"An input function for evaluation or prediction\"\"\"\n",
    "    features=dict(features)\n",
    "    if labels is None:\n",
    "        # No labels, use only features.\n",
    "        inputs = features\n",
    "    else:\n",
    "        inputs = (features, labels)\n",
    "\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
    "\n",
    "    # Batch the examples\n",
    "    assert batch_size is not None, \"batch_size must not be None\"\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    # Return the dataset.\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/31/vyp0jfld0jd1gb8kjcdpn7r00000gn/T/tmp2a0yy4gb\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/31/vyp0jfld0jd1gb8kjcdpn7r00000gn/T/tmp2a0yy4gb', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x182006b6a0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/31/vyp0jfld0jd1gb8kjcdpn7r00000gn/T/tmp2a0yy4gb/model.ckpt.\n",
      "INFO:tensorflow:loss = 129.04485, step = 1\n",
      "INFO:tensorflow:global_step/sec: 480.561\n",
      "INFO:tensorflow:loss = 14.011725, step = 101 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 758.449\n",
      "INFO:tensorflow:loss = 9.920008, step = 201 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 770.215\n",
      "INFO:tensorflow:loss = 6.2131224, step = 301 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 590.242\n",
      "INFO:tensorflow:loss = 6.536858, step = 401 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 707.834\n",
      "INFO:tensorflow:loss = 7.1292644, step = 501 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 841.822\n",
      "INFO:tensorflow:loss = 6.259832, step = 601 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.447\n",
      "INFO:tensorflow:loss = 6.33432, step = 701 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 755.698\n",
      "INFO:tensorflow:loss = 6.2506056, step = 801 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 582.737\n",
      "INFO:tensorflow:loss = 5.015413, step = 901 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 651.631\n",
      "INFO:tensorflow:loss = 5.936748, step = 1001 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 617.291\n",
      "INFO:tensorflow:loss = 6.542171, step = 1101 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 716.548\n",
      "INFO:tensorflow:loss = 4.6751537, step = 1201 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 785.169\n",
      "INFO:tensorflow:loss = 5.404797, step = 1301 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 632.791\n",
      "INFO:tensorflow:loss = 3.22783, step = 1401 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 599.137\n",
      "INFO:tensorflow:loss = 4.815038, step = 1501 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 683.481\n",
      "INFO:tensorflow:loss = 3.196074, step = 1601 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 666.124\n",
      "INFO:tensorflow:loss = 3.3237264, step = 1701 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 749.423\n",
      "INFO:tensorflow:loss = 2.5010073, step = 1801 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 875.703\n",
      "INFO:tensorflow:loss = 4.605499, step = 1901 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 773.951\n",
      "INFO:tensorflow:loss = 3.9477715, step = 2001 (0.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 710.529\n",
      "INFO:tensorflow:loss = 4.319183, step = 2101 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 752.587\n",
      "INFO:tensorflow:loss = 4.787765, step = 2201 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 602.711\n",
      "INFO:tensorflow:loss = 6.5014315, step = 2301 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 757.621\n",
      "INFO:tensorflow:loss = 4.0013204, step = 2401 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 835.968\n",
      "INFO:tensorflow:loss = 4.8451715, step = 2501 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 692.871\n",
      "INFO:tensorflow:loss = 4.0862565, step = 2601 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 593.789\n",
      "INFO:tensorflow:loss = 5.102548, step = 2701 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 616.458\n",
      "INFO:tensorflow:loss = 6.138696, step = 2801 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 608.15\n",
      "INFO:tensorflow:loss = 1.7055767, step = 2901 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 632.988\n",
      "INFO:tensorflow:loss = 4.9958158, step = 3001 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 685.772\n",
      "INFO:tensorflow:loss = 3.8292224, step = 3101 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 760.163\n",
      "INFO:tensorflow:loss = 5.254937, step = 3201 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 604.781\n",
      "INFO:tensorflow:loss = 4.345028, step = 3301 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 637.484\n",
      "INFO:tensorflow:loss = 2.8886595, step = 3401 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 779.051\n",
      "INFO:tensorflow:loss = 2.8511674, step = 3501 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 746.17\n",
      "INFO:tensorflow:loss = 4.215914, step = 3601 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 701.689\n",
      "INFO:tensorflow:loss = 3.5360656, step = 3701 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 762.893\n",
      "INFO:tensorflow:loss = 3.7161415, step = 3801 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 626.057\n",
      "INFO:tensorflow:loss = 4.5930686, step = 3901 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 577.967\n",
      "INFO:tensorflow:loss = 2.8647008, step = 4001 (0.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 561.381\n",
      "INFO:tensorflow:loss = 2.6981194, step = 4101 (0.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 636.072\n",
      "INFO:tensorflow:loss = 4.5889225, step = 4201 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 650.716\n",
      "INFO:tensorflow:loss = 4.9256935, step = 4301 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 798.518\n",
      "INFO:tensorflow:loss = 3.9729466, step = 4401 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 820.546\n",
      "INFO:tensorflow:loss = 2.3535094, step = 4501 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 820.453\n",
      "INFO:tensorflow:loss = 1.1469864, step = 4601 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 716.014\n",
      "INFO:tensorflow:loss = 5.01792, step = 4701 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 655.892\n",
      "INFO:tensorflow:loss = 3.8617709, step = 4801 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 746.854\n",
      "INFO:tensorflow:loss = 4.468909, step = 4901 (0.132 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /var/folders/31/vyp0jfld0jd1gb8kjcdpn7r00000gn/T/tmp2a0yy4gb/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4.2900033.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x182055c860>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_x, train_y), (test_x, test_y) = load_data()\n",
    "\n",
    "train_steps = 5000\n",
    "batch_size = 100\n",
    "my_feature_columns = []\n",
    "for key in train_x.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns,\n",
    "    hidden_units=[10,10],\n",
    "    n_classes=3)\n",
    "\n",
    "classifier.train(\n",
    "    input_fn=lambda:train_input_fn(train_x, train_y, batch_size),\n",
    "    steps=train_steps)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-06-12-12:49:24\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/31/vyp0jfld0jd1gb8kjcdpn7r00000gn/T/tmp2a0yy4gb/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-06-12-12:49:24\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.96666664, average_loss = 0.072312765, global_step = 5000, loss = 2.169383\n"
     ]
    }
   ],
   "source": [
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda:eval_input_fn(test_x, test_y, batch_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set accuracy: 0.967\n",
      "\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/31/vyp0jfld0jd1gb8kjcdpn7r00000gn/T/tmp2a0yy4gb/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "\n",
      "Prediction is \"Setosa\" (99.9%), expected \"Setosa\"\n",
      "\n",
      "Prediction is \"Versicolor\" (100.0%), expected \"Versicolor\"\n",
      "\n",
      "Prediction is \"Virginica\" (99.8%), expected \"Virginica\"\n"
     ]
    }
   ],
   "source": [
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))\n",
    "# Test set accuracy: 0.967\n",
    "\n",
    "# Generate predictions from the model\n",
    "expected = ['Setosa', 'Versicolor', 'Virginica']\n",
    "predict_x = {\n",
    "    'SepalLength': [5.1, 5.9, 6.9],\n",
    "    'SepalWidth': [3.3, 3.0, 3.1],\n",
    "    'PetalLength': [1.7, 4.2, 5.4],\n",
    "    'PetalWidth': [0.5, 1.5, 2.1],\n",
    "}\n",
    "\n",
    "predictions = classifier.predict(\n",
    "    input_fn=lambda:eval_input_fn(predict_x, labels=None, batch_size=batch_size))\n",
    "\n",
    "for pred_dict, expec in zip(predictions, expected):\n",
    "    template = ('\\nPrediction is \"{}\" ({:.1f}%), expected \"{}\"')\n",
    "\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print(template.format(SPECIES[class_id],\n",
    "                          100 * probability, expec))\n",
    "    # Prediction is \"Setosa\" (99.9%), expected \"Setosa\"\n",
    "    # Prediction is \"Versicolor\" (99.7%), expected \"Versicolor\"\n",
    "    # Prediction is \"Virginica\" (95.5%), expected \"Virginica\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
